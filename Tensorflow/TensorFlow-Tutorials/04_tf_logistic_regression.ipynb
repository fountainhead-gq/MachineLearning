{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# get the classic mnist dataset\n",
    "# one-hot means a sparse vector for every observation where only\n",
    "# the class label is 1, and every other class is 0.\n",
    "# more info here:\n",
    "# https://www.tensorflow.org/versions/0.6.0/tutorials/mnist/download/index.html#dataset-object\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000 10000 5000\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# mnist is now a DataSet with accessors for:\n",
    "# 'train', 'test', and 'validation'.\n",
    "# within each, we can access:\n",
    "# images, labels, and num_examples\n",
    "print(mnist.train.num_examples,\n",
    "      mnist.test.num_examples,\n",
    "      mnist.validation.num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784) (55000, 10) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# %% the images are stored as:\n",
    "# n_observations x n_features tensor (n-dim array)\n",
    "# the labels are stored as n_observations x n_labels,\n",
    "# where each observation is a one-hot vector.\n",
    "print(mnist.train.images.shape, mnist.train.labels.shape,mnist.test.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# %% the range of the values of the images is from 0-1\n",
    "print(np.min(mnist.train.images), np.max(mnist.train.images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xbbec0f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiL8QFKEH0iK8ANJEX4gKcIPJPVXNgoaCmspxBAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbb654a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% we can visualize any one of the images by reshaping it to a 28x28 image\n",
    "plt.imshow(np.reshape(mnist.train.images[100, :], (28, 28)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %% We can create a container for an input image using tensorflow's graph:\n",
    "# We allow the first dimension to be None, since this will eventually\n",
    "# represent our mini-batches, or how many images we feed into a network\n",
    "# at a time during training/validation/testing.\n",
    "# The second dimension is the number of features that the image has.\n",
    "n_input = 784\n",
    "n_output = 10\n",
    "net_input = tf.placeholder(tf.float32, [None, n_input])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.nn.softmax(logits, name=None)  `\n",
    "For each batch i and class j we have: `softmax[i, j] = exp(logits[i, j]) / sum(exp(logits[i]))`  \n",
    "$P( y^{(i)} = j|x^{(i)};\\theta) = \\frac{e^{\\theta_j^T}x^{(j)}}{\\sum_{i=1}^k e^{\\theta_j^T}x^{(j)}} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %% We can write a simple regression (y = W*x + b) as:\n",
    "W = tf.Variable(tf.zeros([n_input, n_output]))\n",
    "b = tf.Variable(tf.zeros([n_output]))\n",
    "net_output = tf.nn.softmax(tf.matmul(net_input, W) + b) #预测函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %% We'll create a placeholder for the true output of the network\n",
    "y_true = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %% And then write our loss function:\n",
    "cross_entropy = -tf.reduce_sum(y_true * tf.log(net_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %% This would equate each label in our one-hot vector between the\n",
    "# prediction and actual using the argmax as the predicted label\n",
    "correct_prediction = tf.equal(\n",
    "    tf.argmax(net_output, 1), tf.argmax(y_true, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %% And now we can look at the mean of our network's correct guesses\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %% We can tell the tensorflow graph to train w/ gradient descent using\n",
    "# our loss function and an input learning rate\n",
    "optimizer = tf.train.GradientDescentOptimizer(\n",
    "    0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %% We now create a new session to actually perform the initialization the\n",
    "# variables:\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9224\n",
      "0.9076\n",
      "0.9212\n",
      "0.9228\n",
      "0.9242\n",
      "0.9258\n",
      "0.9232\n",
      "0.922\n",
      "0.9254\n",
      "0.9238\n"
     ]
    }
   ],
   "source": [
    "# %% Now actually do some training:\n",
    "batch_size = 100\n",
    "n_epochs = 10\n",
    "for epoch_i in range(n_epochs):\n",
    "    for batch_i in range(mnist.train.num_examples // batch_size):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(optimizer, feed_dict={\n",
    "            net_input: batch_xs,\n",
    "            y_true: batch_ys\n",
    "        })\n",
    "    print(sess.run(accuracy,\n",
    "                   feed_dict={\n",
    "                       net_input: mnist.validation.images,\n",
    "                       y_true: mnist.validation.labels\n",
    "                   }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9185\n"
     ]
    }
   ],
   "source": [
    "# %% Print final test accuracy:\n",
    "print(sess.run(accuracy,\n",
    "               feed_dict={\n",
    "                   net_input: mnist.test.images,\n",
    "                   y_true: mnist.test.labels\n",
    "               }))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
